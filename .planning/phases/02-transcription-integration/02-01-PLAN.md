---
phase: 02-transcription-integration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/services/cacheService.js
  - src/utils/fileHash.js
  - src/services/transcriptionService.js
autonomous: true
user_setup:
  - service: OpenAI Whisper API
    why: "Speech-to-text transcription with word-level timestamps"
    env_vars:
      - name: OPENAI_API_KEY
        source: "OpenAI Dashboard -> API keys -> Create new secret key"
    account_setup:
      - task: "Create OpenAI account if needed"
        url: "https://platform.openai.com/signup"

must_haves:
  truths:
    - "CacheService can store and retrieve transcript data by file hash"
    - "File hash is stable across sessions for identical content"
    - "TranscriptionService returns word-level timestamps"
    - "Files >25MB are chunked and timestamps remain continuous"
  artifacts:
    - path: "src/utils/fileHash.js"
      provides: "SHA-256 content-based hashing"
      exports: ["generateFileHash"]
    - path: "src/services/cacheService.js"
      provides: "IndexedDB transcript storage"
      exports: ["CacheService"]
    - path: "src/services/transcriptionService.js"
      provides: "Whisper API calls with chunking"
      exports: ["TranscriptionService"]
  key_links:
    - from: "src/services/transcriptionService.js"
      to: "src/services/cacheService.js"
      via: "getCached/setCache calls"
      pattern: "cacheService\\.(get|set)"
    - from: "src/services/transcriptionService.js"
      to: "src/utils/fileHash.js"
      via: "import generateFileHash"
      pattern: "import.*generateFileHash"
---

<objective>
Create backend services for transcription: IndexedDB caching, SHA-256 file hashing, and Whisper API integration with chunking for large files.

Purpose: Establish the data layer for transcription - cache prevents API cost waste, hashing ensures cache hits for identical content, chunking handles files that exceed the 25MB API limit.

Output: Three service modules ready for UI integration in Plan 02.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-transcription-integration/02-RESEARCH.md

# Existing services to follow patterns from
@src/services/audioService.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create CacheService and file hashing utility</name>
  <files>src/utils/fileHash.js, src/services/cacheService.js</files>
  <action>
Create file hash utility using Web Crypto API:

**src/utils/fileHash.js:**
- Export async function `generateFileHash(file)` that:
  - Reads file as ArrayBuffer via `file.arrayBuffer()`
  - Hashes with `crypto.subtle.digest('SHA-256', arrayBuffer)`
  - Returns hex string (64 chars)
- Handle errors gracefully (return null or throw with message)

**src/services/cacheService.js:**
- Create CacheService class with:
  - `constructor()` - initializes IndexedDB via `initDB()` promise
  - `async initDB()` - opens 'PodEditDB' version 1, creates 'transcripts' object store with keyPath 'hash'
  - `async get(fileHash)` - retrieves transcript by hash, returns null if not found
  - `async set(fileHash, transcript)` - stores transcript as JSON string with timestamp
  - Proper transaction management: use oncomplete/onerror listeners, don't await after store operations

Key patterns from research:
- Store transcript as JSON.stringify() to avoid structured cloning overhead
- Use integer version numbers only (not floats)
- Chain operations synchronously within transactions
- Include timestamp in stored record for potential future cache expiry
  </action>
  <verify>
Create test file `test-cache.html` that:
1. Imports both modules
2. Creates a small test file via `new File(['test content'], 'test.txt')`
3. Generates hash, stores a test transcript, retrieves it
4. Console.log success/failure

Run with `npx serve .` and open in browser console.
  </verify>
  <done>
- generateFileHash returns consistent 64-char hex for same content
- CacheService.set stores transcript, CacheService.get retrieves it
- Different file content produces different hash
- Same file content produces same hash across page reloads
  </done>
</task>

<task type="auto">
  <name>Task 2: Create TranscriptionService with Whisper API and chunking</name>
  <files>src/services/transcriptionService.js</files>
  <action>
Create TranscriptionService class that orchestrates transcription:

**Constructor:**
- Accept apiKey parameter (required)
- Store reference to CacheService instance (create internally or accept as param)
- Initialize CacheService

**Main method: `async transcribe(file, onProgress)`**
1. Generate file hash via generateFileHash
2. Check cache first via cacheService.get(hash)
3. If cached, parse JSON and return immediately
4. If file.size > 24 * 1024 * 1024 (24MB - buffer under 25MB limit):
   - Call `transcribeChunked(file, hash, onProgress)`
5. Else call `transcribeSingle(file, hash)`
6. Cache result before returning

**transcribeSingle(file, hash):**
- Build FormData with:
  - 'file': file
  - 'model': 'whisper-1'
  - 'response_format': 'verbose_json'
  - 'timestamp_granularities[]': 'word' (note the array syntax)
- POST to 'https://api.openai.com/v1/audio/transcriptions'
- Headers: Authorization Bearer token
- Parse JSON response
- Cache and return

**transcribeChunked(file, hash, onProgress):**
- Split file using Blob.slice() into 24MB chunks
- For each chunk:
  - Create File object with proper name/type
  - Transcribe via API
  - Track cumulative duration for timestamp offset
  - Adjust word timestamps: word.start += cumulativeDuration, word.end += cumulativeDuration
  - Report progress via onProgress(chunksComplete / totalChunks)
- Merge results: combine text with spaces, flatten words arrays
- Cache merged result

**Error handling:**
- Throw descriptive errors for API failures (include status code)
- Handle network errors gracefully
  </action>
  <verify>
Note: Full verification requires valid OPENAI_API_KEY. For code verification:
1. Review that all methods exist and follow patterns from research
2. Verify FormData construction matches Whisper API requirements
3. Verify chunking logic splits at correct byte boundaries
4. Verify timestamp adjustment adds cumulativeDuration correctly

Manual test when API key available:
```javascript
const service = new TranscriptionService('sk-...');
const transcript = await service.transcribe(audioFile, (progress) => console.log(progress));
console.log(transcript.words.slice(0, 5)); // Should show word-level timestamps
```
  </verify>
  <done>
- TranscriptionService exports correctly
- transcribe() checks cache first, returns cached if exists
- Files under 24MB transcribe in single request
- Files over 24MB split into chunks with continuous timestamps
- onProgress callback receives values 0-1 during chunked transcription
- Results cached after successful transcription
  </done>
</task>

</tasks>

<verification>
All service modules implemented and following patterns from 02-RESEARCH.md:
- [ ] fileHash.js exports generateFileHash using crypto.subtle.digest
- [ ] cacheService.js uses IndexedDB with proper transaction management
- [ ] transcriptionService.js checks cache, handles chunking, adjusts timestamps
- [ ] No ESM import errors when loaded in browser
- [ ] Code matches research patterns for Whisper API verbose_json format
</verification>

<success_criteria>
1. CacheService can store/retrieve transcripts by content hash
2. Same file content always produces same hash (cache key stability)
3. TranscriptionService structure ready for Whisper API calls
4. Chunking logic splits files >24MB correctly
5. Timestamp offset adjustment implemented for chunked transcripts
</success_criteria>

<output>
After completion, create `.planning/phases/02-transcription-integration/02-01-SUMMARY.md`
</output>
