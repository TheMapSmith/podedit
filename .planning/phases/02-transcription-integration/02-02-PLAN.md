---
phase: 02-transcription-integration
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - src/controllers/transcriptController.js
  - index.html
autonomous: false
user_setup: []

must_haves:
  truths:
    - "User can click Generate Transcript button after loading audio"
    - "Progress indicator shows during transcription"
    - "Completed transcript displays with word-level timestamps"
    - "Cached transcript loads immediately without API call"
  artifacts:
    - path: "src/controllers/transcriptController.js"
      provides: "UI state management for transcription"
      exports: ["TranscriptController"]
    - path: "index.html"
      provides: "Transcript section UI"
      contains: "transcript-container"
  key_links:
    - from: "src/controllers/transcriptController.js"
      to: "src/services/transcriptionService.js"
      via: "transcriptionService.transcribe()"
      pattern: "transcriptionService\\.transcribe"
    - from: "index.html"
      to: "src/controllers/transcriptController.js"
      via: "import TranscriptController"
      pattern: "import.*TranscriptController"
---

<objective>
Create TranscriptController for UI state management and integrate transcription UI into the application with progress indication and transcript display.

Purpose: Connect the backend transcription services to the user interface, providing visual feedback during transcription and displaying results with clear timestamps.

Output: Working "Generate Transcript" button that shows progress and displays word-level transcript.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-transcription-integration/02-RESEARCH.md

# Prior plan deliverables
@.planning/phases/02-transcription-integration/02-01-SUMMARY.md

# Existing patterns to follow
@src/components/playerController.js
@index.html
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create TranscriptController</name>
  <files>src/controllers/transcriptController.js</files>
  <action>
Create TranscriptController class following the pattern established by PlayerController:

**Constructor(transcriptionService, elements):**
- Store transcriptionService reference
- Store element references: generateButton, progressContainer, progressBar, progressText, transcriptContainer, errorDisplay
- Initialize state: currentFile = null, transcript = null, isTranscribing = false

**Methods:**

`setFile(file)`:
- Store file reference for transcription
- Enable generate button
- Clear previous transcript display

`async generateTranscript()`:
- Guard: if isTranscribing or no file, return
- Set isTranscribing = true
- Update UI: disable button, show progress container, set progress to 0%
- Clear error display
- Try:
  - Call transcriptionService.transcribe(file, this.onProgress.bind(this))
  - Store result in this.transcript
  - Call renderTranscript()
- Catch:
  - Display error message
- Finally:
  - Set isTranscribing = false
  - Hide progress container
  - Re-enable button

`onProgress(progress)`:
- Update progress bar width: `${Math.round(progress * 100)}%`
- Update progress text: "Transcribing... X%" or "Processing chunk X of Y"

`renderTranscript()`:
- Clear transcriptContainer
- If no transcript or no words, show "No transcript available"
- For each word in transcript.words:
  - Create span element with class 'transcript-word'
  - Set textContent to word.word + ' '
  - Set data-start attribute to word.start
  - Set data-end attribute to word.end
  - Append to container
- Note: Click-to-seek will be added in Phase 3

`formatTimestamp(seconds)`:
- Convert seconds to [MM:SS] or [HH:MM:SS] format
- Reuse pattern from playerController.formatTime or create similar

`getTranscript()`:
- Return current transcript data (for future phases)

`cleanup()`:
- Clear transcript, reset state
  </action>
  <verify>
1. Module exports TranscriptController class
2. All methods defined with correct signatures
3. Progress callback updates UI elements
4. Error handling displays messages without crashing
5. Follows same patterns as PlayerController (separation of concerns)
  </verify>
  <done>
- TranscriptController class exports correctly
- setFile() stores file and enables button
- generateTranscript() orchestrates full flow with progress
- renderTranscript() displays words with timestamp data attributes
- Error states handled gracefully with user feedback
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate transcription UI into index.html</name>
  <files>index.html</files>
  <action>
Add transcription section and wire up TranscriptController:

**HTML additions (after player-controls div):**

```html
<div id="transcription-section" class="transcription-section hidden">
  <div class="transcription-header">
    <h2>Transcript</h2>
    <button id="generate-transcript-btn" disabled>Generate Transcript</button>
  </div>

  <div id="transcription-progress" class="transcription-progress hidden">
    <div class="progress-bar-container">
      <div id="progress-bar" class="progress-bar"></div>
    </div>
    <span id="progress-text">Preparing...</span>
  </div>

  <div id="transcription-error" class="transcription-error"></div>

  <div id="transcript-container" class="transcript-container">
    <p class="transcript-placeholder">Click "Generate Transcript" to transcribe the audio.</p>
  </div>
</div>
```

**CSS additions:**

```css
.transcription-section {
  margin-top: 30px;
  padding: 20px;
  background: #f8f9fa;
  border-radius: 8px;
  border: 1px solid #dee2e6;
}

.transcription-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 15px;
}

.transcription-header h2 {
  font-size: 20px;
  color: #333;
  margin: 0;
}

#generate-transcript-btn {
  padding: 10px 20px;
  font-size: 14px;
  font-weight: 600;
  color: white;
  background: #28a745;
  border: none;
  border-radius: 6px;
  cursor: pointer;
  transition: background 0.2s;
}

#generate-transcript-btn:hover:not(:disabled) {
  background: #218838;
}

#generate-transcript-btn:disabled {
  background: #6c757d;
  cursor: not-allowed;
  opacity: 0.6;
}

.transcription-progress {
  margin-bottom: 15px;
}

.progress-bar-container {
  height: 8px;
  background: #dee2e6;
  border-radius: 4px;
  overflow: hidden;
  margin-bottom: 8px;
}

.progress-bar {
  height: 100%;
  background: #28a745;
  width: 0%;
  transition: width 0.3s ease;
}

#progress-text {
  font-size: 13px;
  color: #6c757d;
}

.transcription-error {
  padding: 12px;
  background: #f8d7da;
  border: 1px solid #f5c6cb;
  border-radius: 4px;
  color: #721c24;
  font-size: 14px;
  margin-bottom: 15px;
}

.transcription-error:empty {
  display: none;
}

.transcript-container {
  max-height: 400px;
  overflow-y: auto;
  padding: 15px;
  background: white;
  border-radius: 4px;
  border: 1px solid #dee2e6;
  line-height: 1.8;
}

.transcript-placeholder {
  color: #6c757d;
  font-style: italic;
}

.transcript-word {
  cursor: default;
  padding: 2px 0;
}

.transcript-word:hover {
  background: #e9ecef;
  border-radius: 2px;
}
```

**JavaScript additions in script module:**

1. Import new modules:
```javascript
import TranscriptionService from './src/services/transcriptionService.js';
import TranscriptController from './src/controllers/transcriptController.js';
```

2. Add element references:
```javascript
transcriptionSection: document.getElementById('transcription-section'),
generateTranscriptBtn: document.getElementById('generate-transcript-btn'),
transcriptionProgress: document.getElementById('transcription-progress'),
progressBar: document.getElementById('progress-bar'),
progressText: document.getElementById('progress-text'),
transcriptionError: document.getElementById('transcription-error'),
transcriptContainer: document.getElementById('transcript-container')
```

3. Initialize services (API key from prompt or env):
```javascript
// For development: prompt for API key or use stored value
let apiKey = localStorage.getItem('openai_api_key');
if (!apiKey) {
  apiKey = prompt('Enter your OpenAI API key:');
  if (apiKey) {
    localStorage.setItem('openai_api_key', apiKey);
  }
}

const transcriptionService = apiKey ? new TranscriptionService(apiKey) : null;
const transcriptController = transcriptionService
  ? new TranscriptController(transcriptionService, {
      generateButton: elements.generateTranscriptBtn,
      progressContainer: elements.transcriptionProgress,
      progressBar: elements.progressBar,
      progressText: elements.progressText,
      transcriptContainer: elements.transcriptContainer,
      errorDisplay: elements.transcriptionError
    })
  : null;
```

4. Wire up file load to show transcription section:
```javascript
// In the existing file change handler, after playerController.onFileLoaded():
if (transcriptController) {
  elements.transcriptionSection.classList.remove('hidden');
  transcriptController.setFile(file);
}
```

5. Wire up generate button:
```javascript
if (transcriptController) {
  elements.generateTranscriptBtn.addEventListener('click', () => {
    transcriptController.generateTranscript();
  });
}
```

6. Update cleanup:
```javascript
window.addEventListener('beforeunload', () => {
  playerController.cleanup();
  if (transcriptController) {
    transcriptController.cleanup();
  }
});
```
  </action>
  <verify>
1. Open index.html with `npx serve .`
2. Upload an audio file - transcription section should appear
3. "Generate Transcript" button should be enabled
4. Click button - should prompt for API key if not stored
5. With valid key: progress bar should animate, transcript should display
6. Without key: should handle gracefully (no crash)
7. Reload page with same file - should load from cache (faster, no progress bar)
  </verify>
  <done>
- Transcription section appears after file upload
- Generate Transcript button is clickable and styled
- Progress bar animates during transcription
- Completed transcript displays with word spans
- Error messages display in error container
- Cached transcripts load immediately without progress
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete transcription integration with caching, progress UI, and word-level transcript display</what-built>
  <how-to-verify>
1. Start dev server: `npx serve .` in project root
2. Open http://localhost:3000 in browser
3. Upload a short audio file (under 1 minute for quick test)
4. Click "Generate Transcript"
5. When prompted, enter your OpenAI API key
6. Verify:
   - Progress bar shows during transcription
   - Transcript appears with individual word spans
   - Each word shows hover effect
7. Refresh the page
8. Upload the SAME audio file again
9. Click "Generate Transcript"
10. Verify: Transcript loads immediately (from cache, no progress bar delay)

For large file test (optional):
11. Upload a file larger than 25MB
12. Verify chunking works (progress shows chunk progress)
  </how-to-verify>
  <resume-signal>Type "approved" if transcription works with caching, or describe any issues</resume-signal>
</task>

</tasks>

<verification>
Phase 2 success criteria validation:
- [ ] User can click "Generate Transcript" and see progress indicator (SC1)
- [ ] User sees completed transcript with word-level timestamps (SC2)
- [ ] Reload with same file loads from cache without re-transcription (SC3)
- [ ] Large files (>25MB) transcribe via chunking without API errors (SC4)
</verification>

<success_criteria>
1. Generate Transcript button triggers transcription flow
2. Progress indicator shows during API processing
3. Transcript displays with word-level spans and data attributes
4. Cache hit loads transcript immediately without API call
5. Files over 25MB handled via chunking with continuous timestamps
</success_criteria>

<output>
After completion, create `.planning/phases/02-transcription-integration/02-02-SUMMARY.md`
</output>
